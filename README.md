**### Make a fork or copy of this repo and fill in your team submission details! ###**

# AMD_Robotics_Hackathon_2025_PickupBuck

## Team Information

**Team:** *Team 33 PickupBuck* 
*Member 1: Ben Taylor*
*Member 2: Win Taylor (Unofficial)*

**Summary:** *Pickup Buck is a Physical AI Suite for cleaning up your room so you don't have to!*

![Example Image 1](/IMG_1671.jpeg)

## Submission Details

### 1. Mission Description
- *The primary application of Pickup Buck is to identify your toys, pick them up and put them away into the PickupBuck(et) that is equipped with a Lerobot robotic arm.*
- *The user can simply say "Pickup, Buck!", "Buck" being the wake-word followed by the identifying command "Pickup", and it will begin the above application.

### 2. Creativity
- *Picking up and placing objects is one of the most fundamental actions in the Physical AI space, but what is unique here is how that function is productized for a younger user to make AI compelling and fun by addressing an everyday pain point for kids.*
- *The ultimate embodiment of PickupBuck is a frictionless and rugged physical product, a bucket with an attached arm and vision censors, that can be placed in a play area and it will perform its functions to the child's delight.*
- *This product can further convey AI concepts to the child by having them "teach" PickupBuck how to clean up. This fun activity will allow the child to frictionlessly generate datasets that can then be processed quickly on the AMD Cloud (WIFI connected by the parent). In no time, the child will have the dual satisfaction of having trained his AI cleanup buddy while also having help to keep a clean room.*

### 3. Technical implementations
- *Teleoperation / Dataset capture*
    - *<Image/video of teleoperation or dataset capture>*
- *Training*
- *Inference*
    - *<Image/video of inference eval>*

### 4. Ease of use
- *At the moment, PickupBuck must be manufactured using Lerobot.*
- *From an end-user standpoint, PickupBuck is easy enough for a child to use, complete with voice-activated functionality, but this can be even further simplified with large single-use buttons.*
- *Primary command is "Pickup, Buck!", but "Line up, Buck!", "Mirror them, Buck!", "Stack them, Buck!", and more planned.*

## Additional Links
*For example, you can provide links to:*

- *Link to a video of your robot performing the task*
- *URL of your dataset in Hugging Face*
- *URL of your model in Hugging Face*
- *Link to a blog post describing your work*

## Code submission

This is the directory tree of this repo, you need to fill in the `mission` directory with your submission details.

```terminal
AMD_Robotics_Hackathon_2025_ProjectTemplate-main/
├── README.md
└── mission
    ├── code
    │   └── <code and script>
    └── wandb
        └── <latest run directory copied from wandb of your training job>
```


The `latest-run` is generated by wandb for your training job. Please copy it into the wandb sub directory of you Hackathon Repo.

The whole dir of `latest-run` will look like below:

```terminal
$ tree outputs/train/smolvla_so101_2cube_30k_steps/wandb/
outputs/train/smolvla_so101_2cube_30k_steps/wandb/
├── debug-internal.log -> run-20251029_063411-tz1cpo59/logs/debug-internal.log
├── debug.log -> run-20251029_063411-tz1cpo59/logs/debug.log
├── latest-run -> run-20251029_063411-tz1cpo59
└── run-20251029_063411-tz1cpo59
    ├── files
    │   ├── config.yaml
    │   ├── output.log
    │   ├── requirements.txt
    │   ├── wandb-metadata.json
    │   └── wandb-summary.json
    ├── logs
    │   ├── debug-core.log -> /dataset/.cache/wandb/logs/core-debug-20251029_063411.log
    │   ├── debug-internal.log
    │   └── debug.log
    ├── run-tz1cpo59.wandb
    └── tmp
        └── code
```

**NOTES**

1. The `latest-run` is the soft link, please make sure to copy the real target directory it linked with all sub dirs and files.
2. Only provide (upload) the wandb of your last success pre-trained model for the Mission.
